{
  "hash": "a57340789020f2c01893f2cfb05f748b",
  "result": {
    "markdown": "---\ntitle: \"Week 4\"\ndescription: \"Expected values of discrete random variables\"\ndate: \"10/16/2023\"\ndate-modified: \"10/18/2023\"\ncategories: [\"\"]\nformat: \n  html:\n    link-external-newwindow: true\n    toc: true\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n<style type=\"text/css\">\n.title{\n  font-size: 40px;\n  color: #006a4e;\n  background-color: #fff;\n  padding: 10px;\n}\n\n.description{\n  font-size: 20px;\n  color: #fff;\n  background-color: #006a4e;\n  padding: 10px;\n}\n</style>\n:::\n\n\n## Resources\n\n+---------+-----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| Chapter | Topic                                               | Slides                                                                                                                 | Annotated Slides                                                                                                                              | Recording                                                                                                                                                                                                                                                                                                                                                         |\n+=========+=====================================================+:======================================================================================================================:+:=============================================================================================================================================:+:=================================================================================================================================================================================================================================================================================================================================================================:+\n| 9       | Independence and Conditioning (Joint Distributions) | [[{{< iconify ri slideshow-fill size=30px >}}](/slides/9_joint_distributions.qmd)]{style=\"color:#f8f5f0;\"}             | [[{{< iconify pepicons-pop pen-circle-filled size=29px >}}](/slides_annotated/09_joint_distributions_02.pdf)]{style=\"color:#f8f5f0;\"}         | [[{{< iconify mdi video size=34px >}}](https://ohsuitg-my.sharepoint.com/personal/wakim_ohsu_edu/_layouts/15/stream.aspx?id=%2Fpersonal%2Fwakim%5Fohsu%5Fedu%2FDocuments%2FTeaching%2FClasses%2FF2023%5FBSTA%5F550%2FRecordings%2F09%5Fjoint%5Fdistributions%5F02%2Emp4&referrer=OneDriveForBusiness&referrerScenario=OpenFile)]{style=\"color:#f8f5f0;\"}          |\n+---------+-----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 10      | Expected Values of discrete RVs                     | [[{{< iconify ri slideshow-fill size=30px >}}](/slides/10_Expected_Values.qmd)]{style=\"color:#f8f5f0;\"}                | [[{{< iconify pepicons-pop pen-circle-filled size=29px >}}](/slides_annotated/10_Expected_Values.pdf)]{style=\"color:#f8f5f0;\"}                | [[{{< iconify mdi video size=34px >}}](https://ohsuitg-my.sharepoint.com/personal/wakim_ohsu_edu/_layouts/15/stream.aspx?id=%2Fpersonal%2Fwakim%5Fohsu%5Fedu%2FDocuments%2FTeaching%2FClasses%2FF2023%5FBSTA%5F550%2FRecordings%2F10%5FExpected%5Fvalues%2Emp4&referrer=OneDriveForBusiness&referrerScenario=OpenFile)]{style=\"color:#f8f5f0;\"}                   |\n+---------+-----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| 11      | Expected Values of *sums of* discrete RVs           | [[{{< iconify ri slideshow-fill size=30px >}}](/slides/11_Expected_Values_of_Sums_of_rvs.qmd)]{style=\"color:#f8f5f0;\"} | [[{{< iconify pepicons-pop pen-circle-filled size=29px >}}](/slides_annotated/11_Expected_Values_of_Sums_of_rvs.pdf)]{style=\"color:#f8f5f0;\"} | [[{{< iconify mdi video size=34px >}}](https://ohsuitg-my.sharepoint.com/personal/wakim_ohsu_edu/_layouts/15/stream.aspx?id=%2Fpersonal%2Fwakim%5Fohsu%5Fedu%2FDocuments%2FTeaching%2FClasses%2FF2023%5FBSTA%5F550%2FRecordings%2F11%5FExpected%5Fvalues%5Fsums%5Fof%5FRVs%2Emp4&referrer=OneDriveForBusiness&referrerScenario=OpenFile)]{style=\"color:#f8f5f0;\"} |\n+---------+-----------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\nFor the slides, once they are opened, if you would like to print or save them as a PDF, the best way to do this is:\n\n1.  Click on the icon with three horizontal bars on the bottom left of the browser.\n2.  Click on \"Tools\" with the gear icon at the top of the sidebar.\n3.  Click on \"PDF Export Mode.\"\n4.  From there, you can print or save the PDF as you would normally from your internet browser.\n\n## On the Horizon\n\n-   [Homework 3 due 10/19 at 11pm](/homework/HW3.qmd)\n\n-   Virtual Class 10/25\n\n-   Midterm 11/1 (in class)\n\n## Announcements\n\n### Announcements on 10/18\n\n-   HW 2 feedback is posted\n\n-   I am converting my Friday office hours to a \"coffee hour\"\n\n    -   This means you can come with any questions, frustrations, ideas, etc. on the program\n\n    -   I will no longer be answering course content questions\n\n-   HW 3\n\n    -   For some reason I took down the answer for NTB #1\n\n        -   It's back up!\n\n        -   Sorry for the confusion!\n\n## Class Exit Tickets\n\n[[{{< iconify healthicons health-worker-form-negative size=30px >}}](https://forms.office.com/Pages/ResponsePage.aspx?id=V3lz4rj6fk2U9pvWr59xWFMopmPUjRtDiHLswhgacNhUMEJVQVc5Rjk2NkhGR0pQOVJQSzAzNlI2Ry4u)]{style=\"color:#f8f5f0;\"} Monday (10/16) *Question about course set up*\n\n[[{{< iconify healthicons health-worker-form-negative size=30px >}}](https://forms.office.com/Pages/ResponsePage.aspx?id=V3lz4rj6fk2U9pvWr59xWFMopmPUjRtDiHLswhgacNhUQlJaRE5FVTZCWDlSTlZYSVFSVzZSVEFFOS4u)]{style=\"color:#f8f5f0;\"} Wednesday (10/18)\n\n## Statistician of the Week: Joy Buolamwini\n\n::: grid\n::: g-col-4\n\n::: {.cell preview='true'}\n::: {.cell-output-display}\n![Joy Buolamwini](../images/stat_of_week/buolamwini.jpg){fig-alt='Image credit: Joy Buolamwini'}\n:::\n:::\n\n:::\n\n::: g-col-8\nDr. Buolamwini earned a BS in Computer Science from Georgia Institute of Technology, an Master's from University of Oxford, and MS and PhD (2022) degrees in Media Arts & Sciences from Massachusetts Institute of Technology. While a graduate student, Dr. Buolamwini was part of the <a href = \"https://www.media.mit.edu/\" target = \"_blank\">MIT Media Lab</a>. Additionally, she is the founder of the <a href = \"https://www.ajl.org/\" target = \"_blank\">Algorithmic Justice League</a>.\n:::\n:::\n\n#### Topics covered\n\nDr. Buolamwini has done substantial work demonstrating how algorithms can encode bias. Her undergraduate senior project was to create a inspired \"mask\" mirror as a way to raise spirits for the person who looked into the mirror. The project relied on off the shelf facial recognition software that could not recognize Dr. Buolamwini's face.\n\nSince then, she has focused her work on demonstrating bias across racial and gender spectra in off the shelf software. Her work has been <a href = \"https://www.biometricupdate.com/202003/tech-giants-pressured-to-follow-google-in-removing-gender-labels-from-computer-vision-services\" target = \"_blank\">cited</a> as directly influencing Microsoft and Google's changes to their algorithms.\n\nAmong many other aspects, a big focus of Dr. Buolamwini's work is pointing out the biased data which directly impacts how algorithms learn how to do tasks.\n\n#### Relevant work\n\n-   Buolamwini, J., Gebru, T. <a href = \"https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf\" target = \"_blank\">Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.</a> Proceedings of Machine Learning Research 81:1--15, 2018 Conference on Fairness, Accountability, and Transparency.\n\n-   Raji, I & Buolamwini, J. <a href = \"https://doi.org/10.1145/3306618.3314244\" target = \"_blank\">Actionable Auditing: Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products.</a> Conference on Artificial Intelligence, Ethics, and Society, 2019\n\n#### Outside links\n\n-   [Wikipedia](https://en.wikipedia.org/wiki/Joy_Buolamwini)\n-   [Linkedin](https://www.linkedin.com/in/buolamwini/)\n-   [personal](https://www.poetofcode.com/)\n\n#### Other\n\nDr. Buolamwini has done a lot of work on how data propagates through systems to encode the same types of bias into different algorithms. In her video <a href = \"https://www.youtube.com/watch?v=QxuyfWoVV98\" target = \"_blank\">AI, Ain't I a Woman?</a> she demonstrates how systems designed to determine gender are particularly poor when using dark skinned faces.\n\nHer work was featured in a recent documentary <a href = \"https://www.codedbias.com/\" target = \"_blank\">Coded Bias</a>.\n\n**Please note the statisticians of the week are taken directly from the [CURV project by Jo Hardin](https://hardin47.github.io/CURV/).**\n\n## Muddiest Points\n\n### 1. How does this link to more real life applications? Isn't this the same as the previous chapters, but with new notation?\n\nWe'll see a better application in homework 4 (but don't worry, it won't be overly complicated).\n\nSo far, yes, the joint distribution we have done with discrete random variables have been very similar to the examples with events A and B. This is mostly meant to guide us through some of the new and difficult notation. You can think of our work so far with pmf's and CDFs as a way to rewrite and reframe the previous problems we have looked at. This reframing is going to help us when we start looking at continuous random variables.\n\n### 2. Notation is hard to get down!\n\n#### What is F? Is it a function?\n\nYes, it is! It is the function: $$F_X(x) = \\mathbb{P}(X \\leq x)$$\n\nThe CDF stands for cumulative distribution function, which we write in math terms as $F_X(x)$. The CDF is the probability that $X$ will take a value less than or equal to $x$. Just like the pmf, the sample space is defined by $X$, but the range of values that $F$ maps to is 0 to 1, and is increasing as $x$ increases.\n\n#### What's an RV and what's the value that an RV takes on?\n\nHere's what I wrote in Week 3 Muddy Points:\n\n-   What's the difference between $X(\\omega)$ (random variable) and $x$ (the value of the random varaible)?\n\n    -   In class we defined $X(\\omega) = x$. We call $X(\\omega)$ or $X$ the random variable and $x$ the realized value of that random variable.\n\n    -   For example: If I roll 20 dice, what is the number of dice that come up with 6?\n\n        -   $X$ (or $X(\\omega)$) is the number of 6's that come up\n\n        -   $x$ is the realized value (like 4 dice have 6's) that can be observed\n\n        -   The number of 6's ($X$ or $X(\\omega)$) is not yet a realized value, but it can be any of the realized values, $x$! Thus, we write $X = x$.\n\n    -   I thought [this Reddit thread](https://www.reddit.com/r/learnmath/comments/4ti8nm/what_is_the_difference_between_x_and_x_in_regards/) is pretty helpful!\n\n#### pmf vs. CDF: takes practice to remember the difference\n\nFor this, I'd say practice helps the most to distinguish between them.\n\n+----------------------------+--------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+\n|                            | pmf                                                                                  | CDF                                                                         |\n+============================+======================================================================================+=============================================================================+\n| Math representation        | $p_X(x)$                                                                             | $F_X(x)$                                                                    |\n+----------------------------+--------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+\n| Definition                 | $p_X(x) = \\mathbb{P}(X=x) = \\\\ \\mathbb{P}(\\mathrm{all }\\ \\omega\\in S:X(\\omega) = x)$ | $F_X(x) = \\mathbb{P}(X \\leq x) = \\sum \\limits_{\\{all\\ l:\\ l\\leq x\\}}p_X(l)$ |\n+----------------------------+--------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+\n| Spoken meaning of math rep | The probability that X equals \\_\\_\\_.                                                | The probability that X is less than or equal to \\_\\_\\_\\_.                   |\n+----------------------------+--------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+\n| Properties                 | -   Range from 0 to 1                                                                | -   CDF is increasing or the same                                           |\n|                            |                                                                                      |                                                                             |\n|                            | -   Sum of pmf across all $x$ values is 1                                            | -   Range from 0 to 1                                                       |\n|                            |                                                                                      |                                                                             |\n|                            |                                                                                      | -   The max value of the CDF is 1                                           |\n|                            |                                                                                      |                                                                             |\n|                            |                                                                                      | -   The minimum value of the CDF is 0                                       |\n+----------------------------+--------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+\n\nI really suggest that you do this kind of table for all the different probabilities that we've identified so far:\n\n-   $p_{X,Y}(x,y)$\n\n-   $F_{X,Y}(x,y)$\n\n-   $p_{X|Y}(x|y)$\n\n-   $F_{X|Y}(x|y)$\n\n### 3. For the drawing $200$ cards example: why $x = 0, 1, 2, ..., 200$ but $i = 1, 2, 3, ...,200$ instead of $201$? Doesn't that mean we're summing over a shorter interval?\n\nYes! The interval that we sum over will be 1 to 200, but this will still cover all the x values from 0 to 200. When we sum over $i=1, 2, 3, …, 200$ draws, if all 200 the draws (all $Y_i$'s) come up with cards that are not hearts, then the sum is 0 ($\\sum_{i=1}^{200} Y_i = 0$). Thus, $x$ can still take on a 0 value.\n\n### 4. I got a little tripped up on what $a_i$ means in theorem 11.1: sum of discrete RVs. Wouldn't it just be an $a$? Or is it $a_i$ because it's a different constant (the probability?) for each $X_i$?\n\nIt would not be $a$ (without the $i$). It *is* because $a_i$ represents a different constant for each $X_i$! So you are right! However, $a_i$ is not a probability. This is where the expected value gets a little confusing with all the sums. The expected value of a single random variable is defined by $E[X_1] = \\sum_{j=1}^{m} x_j p_{X_1}(x_j)$, where $m$ is the total number of values $X_1$ can take and $j$ is the $jth$ value of $X_1$. Then if we want to look at the expected value of the sum of $X_1$ and $X_2$, We look at $E\\bigg[\\sum_{i=1}^{2} X_i\\bigg] =E[X_1 + X_2] =E[X_1] + E[X_2]=\\sum_{j=1}^{m} x_j p_{X_1}(x_j) + \\sum_{k=1}^{h} x_k p_{X_2}(x_k)$. If we then wanted to look at the expected value of the sum of $3\\times X_1$ and $2 \\times X_2$, we could write: $E\\bigg[\\sum_{i=1}^{2} a_i X_i\\bigg] =E[3X_1 + 2X_2] =E[3X_1] + E[2X_2]=3E[X_1] + 2E[X_2]= 3\\sum_{j=1}^{m} x_j p_{X_1}(x_j) + 2\\sum_{k=1}^{h} x_k p_{X_2}(x_k)$\n\n### 5. Expected value for our examples with and without replacement (and then also with finite and infinite draws)\n\nWorking on a better explanation for this one!\n\nThere are a few distinctions here:\n\n1.  with replacement vs. without replacement\n\n2.  draw finite number vs. draw until we get some \\# of \"successes\" (infinite)\n\nLet's start with our ghost example from Chapter 11 notes:\n\n> The ghost is trick-or-treating at a different house now. In this case it is known that the bag of candy has 10 chocolates, 20 lollipops, and 30 laffy taffies. The ghost grabs a *handful of five pieces of candy.* How many pieces of chocolate do we expect the ghost to take?\n\nIn the above problem, I tried to intentionally word it so that we are simultaneously sampling all five candies instead of drawing one candy then another then another... However, this is still confusing. So let's just say with and without replacement. We have two options for our problem:\n\n1.  The ghost takes five pieces of candy *with replacement*\n\n2.  The ghost takes five pieces of candy *without replacement*\n\n+-----------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------+\n| With replacement                                                                              | Without replacement                                                                                       |\n+===============================================================================================+===========================================================================================================+\n| Because the probability is the same between draws, the Bernoulli distributions are identical: | I struggled with showing this without using counting, so here it is solved using the Chapter 10 approach: |\n|                                                                                               |                                                                                                           |\n| ![](week_04/ghost_w_replacement.jpeg)                                                         | ![](week_04/without_rep_01.jpeg)                                                                          |\n|                                                                                               |                                                                                                           |\n| ![](week_04/ghost_w_replacement_02.jpeg)                                                      | $p_X(x)$ above is only for $x=0, 1, 2, 3, 4, 5$                                                           |\n|                                                                                               |                                                                                                           |\n|                                                                                               | ![](week_04/without_rep_02.jpg)                                                                           |\n+-----------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------+\n\nThe final expected values for BOTH are the same!! Why are they the same???\n\nIf you go back to the \"with replacement\" and try to use counting to solve the expected value, we can start with $$p_X(x) = \\dfrac{{10+x-1 \\choose x}{50 + (5-x) -1 \\choose 5-x}}{{60 + 5 -1 \\choose 5}}$$\n\nwhich comes from the last of the [Chapter 22 slides](/slides/22_Counting_Intro.qmd). For order does not matter and with replacement we count possibilities using ${n+r-1 \\choose r}$.\n\nThen the expected value of $X$ using this probability is $$E\\Bigg[\\sum_{x=0}^5 x p_X(x)\\Bigg]$$ which also equals $5/6$!!\n\n$$ \\begin{align} E\\Bigg[\\sum_{x=0}^5 x p_X(x)\\Bigg] & =  0p_X(0)+1p_X(0)+2p_X(0)+3p_X(0)+4p_X(0)+5p_X(5) \\\\ & = 1\\dfrac{{10 \\choose 1}{50 + 4 -1 \\choose 4}}{{60 + 5 -1 \\choose 5}} + 2\\dfrac{{10+1 \\choose 2}{50 + 3 -1 \\choose 5-2}}{{60 + 5 -1 \\choose 5}}+3\\dfrac{{10+2 \\choose 3}{50 + 2 -1 \\choose 2}}{{60 + 5 -1 \\choose 5}}+ \\\\ & \\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }\\text{ }4\\dfrac{{10+4-1 \\choose 4}{50 + (5-4) -1 \\choose 5-4}}{{60 + 5 -1 \\choose 5}}+5\\dfrac{{10+5-1 \\choose 5}{50 + (5-5) -1 \\choose 5-5}}{{60 + 5 -1 \\choose 5}} \\\\ & = \\dfrac{5}{6}\\end{align}$$\n\nThis still does not quite answer why they are the same. I'm going to continue to work on this one!\n\n### 6. For corollary 11.1.2, when it says the random variables are identically distributed, does that also mean the random variables must be independent as well?\n\nNo! So this is a special property of expected values called the *linearity of expected values*. It means that no matter if the random variables are dependent, the expected value of the sum (of RVs) is the sum of the expected values of RVs. So when the random variables are identically distributed, the expected value of each is the same. Hence, the corollary. The fact that they are dependent does not change the corollary!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}