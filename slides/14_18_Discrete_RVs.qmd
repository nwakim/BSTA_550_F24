---
title: "Chapter 14, 15, 16, 19, 20: Some Important Discrete RVs"
author: "Meike Niederhausen and Nicky Wakim"
date: "10/25/2023"
categories: ["Week 5"]
title-slide-attributes:
    data-background-color: "#006a4e"
format: 
  revealjs:
    theme: [default, simple_NW.scss]
    toc: true
    chalkboard: true
    slide-number: true
    show-slide-number: all
    width: 1955
    height: 1100
    footer: Chapter 14-16, 19-20 Slides
editor: 
  markdown: 
    wrap: 72
---

## Learning Objectives

1.  Distinguish between Bernoulli, Binomial, Geometric, Hypergeometric,
    and Discrete Uniform distributions when reading a story.
2.  Identify the variable and the parameters in a story, and state what
    the variable and parameters mean.
3.  Use the formulas for the pmf/CDF, expected value, and variance to
    answer questions and find probabilities.

# Chapter 14: Bernoulli RVs

## Properties of Bernoulli RVs

-   **Scenario:** One trial, with outcome success or failure
-   Shorthand: $X \sim \text{Bernoulli}(p)$

$$
X = \left\{
        \begin{array}{ll}
            1 & \quad \mathrm{with\ probability}\ p \quad \\
            0 & \quad \mathrm{with\ probability}\ 1-p \quad
        \end{array}
    \right.
$$

$$
p_X(x) = P(X=x) = p^x(1-p)^{1-x} \text{ for } x=0,1
$$

$$\text{E}(X) = p$$

$$\text{Var}(X) = pq = p(1-p)$$

## Bernoulli Example 1

::: columns
::: {.column width="35%"}
::: example
::: ex-title
Example 1
:::

::: ex-cont
-   We roll a fair 6-sided die.

-   We get \$1 if we roll a 5, and nothing otherwise.

-   Let $X$ be how much money we get.

-   Find the mean and variance of $X$.
:::
:::
:::
:::

# Chapter 15: Binomial RVs {#chapter-15-binomial-r.v.s .unnumbered}

## Properties of Binomial RVs

-   **Scenario:** There are $n$ independent trials, each resulting in a
    success or failure, with constant probability, $p$, in each trial.
    We are counting the number of successes (or failures).

-   Shorthand: $X \sim \text{Binomial}(n, p)$

$$
X = \text{Number of successes of } n \text{ independent trials}
$$

$$
p_X(x) = P(X=x) = {n \choose x}p^x(1-p)^{n-x} \text{ for } x=0,1,2,  ..., n
$$

$$\text{E}(X) = np$$ $$\text{Var}(X) = npq = np(1-p)$$

## Bernoulli to Binomial

::: columns
::: {.column width="35%"}
::: example
::: ex-title
Example 2
:::

::: ex-cont
-   Suppose we roll a fair 6-sided die 50 times.

-   We get \$1 every time we roll a 5, and nothing otherwise.

-   Let $X$ be how much money we get on the 50 rolls.

-   Find the mean and variance of $X$.
:::
:::
:::
:::

# Chapter 16: Geometric RVs {#chapter-16-geometric-r.v.s .unnumbered}

## Geometric RVs

-   **Scenario:** There are repeated independent trials, each resulting
    in a success or failure, with constant probability of success for
    each trial. We are counting the number of trials until the first
    success.

-   Shorthand: $X \sim \text{Geo}(p)$ or $X \sim \text{Geometric}(p)$ or
    $X \sim \text{G}(p)$

+-----------------------------------+-------------------------------+
| $X =$ Number of trials needed for | $X =$ Number of failures      |
| first success (count $x$          | before first success (count   |
| *includes* the success)           | $x$ *does not include* the    |
|                                   | success)                      |
+:=================================:+:=============================:+
| $p                                | $                             |
| _X ( x ) = P(X=x) = (1-p)^{x-1}p$ | p_X (x)= P(X=x) = (1-p)^{x}p$ |
|                                   |                               |
| for $x=1,2, 3,...$                | for $x=0, 1,2,...$            |
|                                   |                               |
| $F_                               | $F_X ( x )                    |
| X ( x ) = P(X\leq x) = 1-(1-p)^x$ | = P(X\leq x) = 1-(1-p)^{x+1}$ |
|                                   |                               |
| for $x=1,2, 3,...$                | for $x=0, 1,2,...$            |
+-----------------------------------+-------------------------------+
| $E(X)=\dfrac{1-p}{p}$             | $E(X)=\dfrac{1-p}{p}$         |
|                                   |                               |
| $Var(X)= \dfrac{1-p}{p^2}$        | $Var(X) = \dfrac{1-p}{p^2}$   |
+-----------------------------------+-------------------------------+

## Bullseye (1/6)

::: columns
::: {.column width="100%"}
::: example
::: ex-title
Example 3
:::

::: ex-cont
We throw darts at a dartboard until we hit the bullseye. Assume throws
are independent and the probability of hitting the bullseye is 0.01 for
each throw.

1.  What is the pmf for the number of throws needed to hit the bullseye?

2.  What are the mean and variance for the number of throws needed to
    hit the bullseye?

3.  Find the probability that our first bullseye:

    -   is on the fourth try

    -   is on one of the first four tries

    -   is after the fifth try

    -   is on one of the first fifty tries

    -   is after the $50^{th}$ try, given that it did not happen on the
        first 20 tries

4.  Find the expected number of misses until we hit the bullseye.
:::
:::
:::
:::

## Bullseye (2/6)

::: columns
::: {.column width="35%"}
::: example
::: ex-title
Example 3
:::

::: ex-cont
We throw darts at a dartboard until we hit the bullseye. Assume throws
are independent and the probability of hitting the bullseye is 0.01 for
each throw.

1.  What is the pmf for the number of throws needed to hit the bullseye?
:::
:::
:::
:::

## Bullseye (3/6)

::: columns
::: {.column width="35%"}
::: example
::: ex-title
Example 3
:::

::: ex-cont
We throw darts at a dartboard until we hit the bullseye. Assume throws
are independent and the probability of hitting the bullseye is 0.01 for
each throw.

2.  What are the mean and variance for the number of throws needed to
    hit the bullseye?
:::
:::
:::
:::

## Bullseye (4/6)

::: columns
::: {.column width="35%"}
::: example
::: ex-title
Example 3
:::

::: ex-cont
We throw darts at a dartboard until we hit the bullseye. Assume throws
are independent and the probability of hitting the bullseye is 0.01 for
each throw.

3.  Find the probability that our first bullseye:

    -   is on the fourth try

    -   is on one of the first four tries

    -   is after the fourth try
:::
:::
:::
:::

## Bullseye (5/6)

::: columns
::: {.column width="35%"}
::: example
::: ex-title
Example 3
:::

::: ex-cont
We throw darts at a dartboard until we hit the bullseye. Assume throws
are independent and the probability of hitting the bullseye is 0.01 for
each throw.

3.  Find the probability that our first bullseye:

    -   is on one of the first fifty tries

    -   is after the $50^{th}$ try, given that it did not happen on the
        first 20 tries
:::
:::
:::
:::

## Memoryless property for Geometric RVs

If we know $X$ is greater than some number (aka given $X >j$), then the
probability of $X > k+j$ is just the probability that $X>k$.

$P(X > k+j |X > j) = P(X > k)$
$$ P(X > k+j |X > j) = \dfrac{P(X>k+j \text{ and } X>j)}{P(X>j)} = \dfrac{P(X>k+j)}{P(X>j)} = \dfrac{(1-p)^{k+j}}{(1-p)^{j}} = (1-p)^{k} $$

# Chapter 19: Hypergeometric RVs {#chapter-19-hypergeometric-r.v.s .unnumbered}

## Hypergeometric RVs

-   **Scenario:** There are a fixed number of successes and failures
    (which are known in advance), from which we make $n$ draws without
    replacement. We are counting the number of successes from the $n$
    trials.
    -   There is a finite population of $N$ items
    -   Each item in the population is either a success or a failure,
        and there are $M$ successes total.
    -   We randomly select (sample) $n$ items from the population.
-   Shorthand: $X \sim \text{Hypergeo}(M, N, n)$

::: columns
::: column
$$
X = \text{Number of successes in } n \text{ draws}
$$

$$
p_X(x) = P(X=x) = \dfrac{{M \choose x}{N-M \choose n-x}}{{N \choose n}} 
$$
$$\text{ for } x \text{ integer-valued } \\ \max(0, n-(N-M)) \leq x \leq \min(n, M)$$
:::

::: column
$$\text{E}(X) =\dfrac{nM}{N}$$

$$\text{Var}(X) = n \dfrac{M}{N} \bigg(1- \dfrac{M}{N} \bigg)\bigg(\dfrac{N-n}{N-1} \bigg)$$
:::
:::

## Wolf population

::: columns
::: {.column width="35%"}
::: example
::: ex-title
Example 4
:::

::: ex-cont
A wildlife biologist is using mark-recapture to research a wolf
population. Suppose a specific study region is known to have 24 wolves,
of which 11 have already been tagged. If 5 wolves are randomly captured,
what is the probability that 3 of them have already been tagged?
:::
:::
:::
:::

## Hypergeometric vs. Binomial RVs

Suppose a hypergeometric RV $X$ has the following properties:

-   the population size $N$ is really big,

-   the number of successes $M$ in the population is relatively large,

    -   $\frac{M}{N}$ shouldn't be close to 0 or 1

-   and the number of items $n$ selected is small.

Then, in this case, making $n$ draws from the population doesn't change
the probability of success much, and the hypergeometric r.v. can be
approximated by a binomial r.v.

## Wolf population revisited

::: columns
::: {.column width="28%"}
::: example
::: ex-title
Example 5
:::

::: ex-cont
Suppose a specific study region is known to have 2400 wolves, of which
1100 have already been tagged.

1.  If 50 wolves are randomly captured, what is the probability that 20
    of them have already been tagged?

2.  Approximate the probability in part (1) using the binomial
    distribution.
:::
:::
:::
:::

# Chapter 20: Discrete Uniform RVs {#chapter-20-discrete-uniform-r.v.s .unnumbered}

## Discrete Uniform RVs

-   **Scenario:** There are $N$ possible outcomes, which are all equally
    likely.
-   Shorthand: $X \sim \text{Uniform}(N)$

$$
X = \text{Outcome of interest, with } x=1, 2, ..., N
$$

$$
p_X(x) = P(X=x) = \dfrac{1}{N} \text{ for } x=1, 2, 3, ..., N
$$

$$\text{E}(X) =\dfrac{N+1}{2}$$

$$\text{Var}(X) = \dfrac{N^2 -1}{12}$$

## What discrete uniform RVs have we seen already?

::: columns
::: {.column width="35%"}
::: example
::: ex-title
Example 6
:::

::: ex-cont
Examples of discrete uniform RVs
:::
:::
:::
:::
